{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upU8iWtojlkk"
   },
   "source": [
    "# 6.2. Случайный лес\n",
    "\n",
    "Ваша задача - написать класс `random_forest` для решения задачи классификации на основе датасета Ирисов Фишера (`sklearn.datasets.load_iris`), принимающий на вход конструктора аргументы `n_estimators`, `max_depth`, `subspaces_dim` и `random_state`. описание этих аргументов приведено ниже. У этого класса должны быть определены методы `.fit()` и `.predict()`, а также поле `._estimators`, в котором должен храниться список алгоритмов, используемых в ансамбле. \n",
    "\n",
    "Для создания обучающей подвыборки для каждого из базовых классификаторов, Вы можете воспользоваться классом `sample`, который Вы реализовали в прошлом задании. В случае его использования, не забудьте включить его описание в файл с Вашим решением текущего задания. Мы также предлагаем вам организовать выбор подпространств для каждого дерева посредством заполнения списка `subspace_idx`, в котором будут логироваться выбранные для каждого базового классификатора подпространства.\n",
    "\n",
    "Замечание: в рамках выполнения данного задания запрещено использовать класс `sklearn.ensemble.RandomForestClassifier`. Такой код не пройдёт проверку.\n",
    "\n",
    "Подберите также гиперпараметры, на которых ваш алгоритм получает наилучшее качество (с точки зрения метрики accuracy, доли правильных ответов) на тестовой выборке с параметром `test_size`=0.3, задайте их в виде глобальных переменных N_ESTIMATORS, MAX_DEPTH, SUBSPACE_DIM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GLfTj8FHjvY2",
    "outputId": "15abc519-477c-4e4e-e386-43cefd457bff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:58<00:00,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 6 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "class sample(object):\n",
    "  def __init__(self, X, n_subspace):\n",
    "    self.idx_subspace = self.random_subspace(X, n_subspace)\n",
    "  \n",
    "  def __call__(self, X, y):\n",
    "    idx_obj = self.bootstrap_sample(X)\n",
    "    X_sampled, y_sampled = self.get_subsample(X, y, self.idx_subspace, idx_obj)\n",
    "    return X_sampled, y_sampled\n",
    "\n",
    "  @staticmethod\n",
    "  def bootstrap_sample(X, random_state=42):\n",
    "    \"\"\"\n",
    "    Заполните тело этой функции таким образом, чтобы она возвращала массив индексов выбранных при помощи бэггинга индексов.\n",
    "    Пользуйтесь только инструментами, реализованными в numpy.random, выставляя везде, где это необходимо, random_state=42\n",
    "    \"\"\"\n",
    "    return np.unique(np.random.choice(len(X), len(X)))\n",
    "  @staticmethod\n",
    "  def random_subspace(X, n_subspace, random_state=42):\n",
    "    \"\"\"\n",
    "    Заполните тело этой функции таким образом, чтобы она возвращала массив индексов выбранных при помощи метода случайных подпространств признаков\n",
    "    Количество этих признаков передается при помощи аргумента n_subspace\n",
    "    Пользуйтесь только инструментами, реализованными в numpy.random, выставляя везде, где это необходимо, random_state=42\n",
    "    \"\"\"\n",
    "    return np.random.choice(len(X[0]), n_subspace, replace=False)\n",
    "\n",
    "  @staticmethod\n",
    "  def get_subsample(X, y, idx_subspace, idx_obj):\n",
    "    \"\"\"\n",
    "    Заполните тело этой функции таким образом, чтобы она возвращала подвыборку x_sampled, y_sampled \n",
    "    по значениям индексов признаков(idx_subspace) и объектов(idx_obj) , которые должны в неё попасть\n",
    "    \"\"\"\n",
    "    x_sampled=X[np.ix_(idx_obj, idx_subspace)]\n",
    "    y_sampled=y[np.array(idx_obj)]\n",
    "    return x_sampled,y_sampled\n",
    "\n",
    "\n",
    "\n",
    "class random_forest(object):\n",
    "  def __init__(self, n_estimators: int, max_depth: int, subspaces_dim: int, random_state: int):\n",
    "    self.n_estimators = n_estimators\n",
    "    self.max_depth = max_depth\n",
    "    self.subspaces_dim = subspaces_dim\n",
    "    self.random_state = random_state\n",
    "    self.trees=[]\n",
    "    self.subspace_idx=[]\n",
    "\n",
    "  def fit(self, X, y):\n",
    "    for i in range(self.n_estimators):\n",
    "      s = sample(X, self.subspaces_dim)\n",
    "      bootstrap_indices = s.bootstrap_sample(X)\n",
    "      X_sampled, y_sampled = s.get_subsample(X, y, s.idx_subspace, bootstrap_indices)\n",
    "      self.subspace_idx.append(s.idx_subspace)\n",
    "      clf = DecisionTreeClassifier(max_depth=self.max_depth, random_state=self.random_state)\n",
    "      clf.fit(X_sampled, y_sampled)\n",
    "      self.trees.append(clf)\n",
    "    self.trees=np.array(self.trees)\n",
    "    self.subspace_idx=np.array(self.subspace_idx)\n",
    "  def predict(self, X):\n",
    "    ans=[]\n",
    "    for x in X :\n",
    "      dict=[]\n",
    "      x=np.array(x)\n",
    "      x=x[np.newaxis, :]\n",
    "      for i in range(self.n_estimators):\n",
    "        dict.append(self.trees[i].predict(x[np.ix_([0], self.subspace_idx[i])]))\n",
    "      values, counts = np.unique(np.array(dict), return_counts=True)\n",
    "      ans.append(values[np.argmax(counts)])\n",
    "    return np.array(ans)\n",
    "data = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.3, stratify=data.target, random_state=42)\n",
    "\n",
    "N_ESTIMATORS=[1, 2, 3, 4,  5, 6, 7 ,8, 9 ,10, 11, 12, 13, 14,15,  16, 17, 19]#, 22, 23, 24,  25, 26, 27, 28, 31, 35, 40 , 45, 46, 46, 48, 49, 50]\n",
    "MAX_DEPTH=[1, 2, 3, 4,  5, 6, 7 ,8, 9 ,10, 11, 12, 13, 14,15,  16, 17, 19]#, 22, 23, 24,  25, 26, 27, 28, 31, 35, 40 , 45, 46, 46, 48, 49, 50]\n",
    "SUBSPACE_DIM=[1, 2, 3, 4]\n",
    "max=-1\n",
    "for i in tqdm(N_ESTIMATORS):\n",
    "  for j in MAX_DEPTH:\n",
    "    for k in SUBSPACE_DIM:\n",
    "      rf=random_forest(n_estimators=i, max_depth=j, subspaces_dim=k, random_state=42)\n",
    "      rf.fit(X_train, y_train)\n",
    "      ans=rf.predict(X_test)\n",
    "      #print(len(ans), len(y_test))\n",
    "      acc=accuracy_score(y_test, ans)\n",
    "      if acc>max :\n",
    "        max=acc\n",
    "        max_i=i\n",
    "        max_j=j\n",
    "        max_k=k\n",
    "print(max_i, max_j, max_k)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
